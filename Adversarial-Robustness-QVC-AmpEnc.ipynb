{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1f78dc",
   "metadata": {
    "id": "ad1f78dc"
   },
   "source": [
    "# Amplitude Encoding Variational Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2928c0e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2928c0e9",
    "outputId": "1d87ef45-a6f8-49a2-c445-9d82bf40efdb"
   },
   "outputs": [],
   "source": [
    "from visualizer import *\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca05643",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ca05643",
    "outputId": "8ae8ccae-391b-4a42-ba5f-5a95300f21e9"
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "            transforms.Resize(size=18),\n",
    "            transforms.CenterCrop(size=16),\n",
    "            transforms.ToTensor()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c11dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.ImageFolder(root='./dataset/dataset_train', transform=transform)\n",
    "test = datasets.ImageFolder(root='./dataset/dataset_test', transform=transform)\n",
    "rng = np.random.default_rng(seed=123401234)\n",
    "num_classes = 4\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=len(train))\n",
    "test_loader = DataLoader(test, batch_size=len(test))\n",
    "\n",
    "train_set_img, train_set_labels = next(iter(train_loader))\n",
    "test_set_img, test_set_labels = next(iter(test_loader))\n",
    "\n",
    "train_set_img = torch.squeeze(train_set_img[:,0,:,:])\n",
    "test_set_img = torch.squeeze(test_set_img[:,0,:,:])\n",
    "\n",
    "\n",
    "# permute the arrays so we can visualize different classes with first 10 imgs\n",
    "rand_idx_train = rng.permutation(len(train_set_img))\n",
    "X_train = train_set_img[rand_idx_train]\n",
    "Y_train = train_set_labels[rand_idx_train]\n",
    "\n",
    "rand_idx_test = rng.permutation(len(test_set_img))\n",
    "X_test = test_set_img[rand_idx_test]\n",
    "Y_test = test_set_labels[rand_idx_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16761fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain = datasets.MNIST('./dataset', train=True, download=True,\\n                       transform=transform)\\ntest = datasets.MNIST('./dataset', train=False,\\n                       transform=transform)\\n\\ntrain_loader = DataLoader(train, batch_size=len(train))\\ntest_loader = DataLoader(test, batch_size=len(test))\\n\\ntrain_set_img, train_set_labels = next(iter(train_loader))\\ntest_set_img, test_set_labels = next(iter(test_loader))\\n\\nX_train = train_set_img\\nX_test = test_set_img\\nY_train = train_set_labels\\nY_test = test_set_labels\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train = datasets.MNIST('./dataset', train=True, download=True,\n",
    "                       transform=transform)\n",
    "test = datasets.MNIST('./dataset', train=False,\n",
    "                       transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=len(train))\n",
    "test_loader = DataLoader(test, batch_size=len(test))\n",
    "\n",
    "train_set_img, train_set_labels = next(iter(train_loader))\n",
    "test_set_img, test_set_labels = next(iter(test_loader))\n",
    "\n",
    "X_train = train_set_img\n",
    "X_test = test_set_img\n",
    "Y_train = train_set_labels\n",
    "Y_test = test_set_labels\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe831e6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe831e6f",
    "outputId": "a3976827-8484-45e1-cda0-fc2651934100"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shapes: X_train_input: torch.Size([1000, 256]), X_test_input: torch.Size([200, 256]),Y_train_input: torch.Size([1000]), Y_test_input: torch.Size([200])\n",
      "number of samples with label 0 in train set: 250\n",
      "number of samples with label 1 in train set: 250\n",
      "number of samples with label 2 in train set: 250\n",
      "number of samples with label 3 in train set: 250\n",
      "number of samples with label 0 in test set: 50\n",
      "number of samples with label 1 in test set: 50\n",
      "number of samples with label 2 in test set: 50\n",
      "number of samples with label 3 in test set: 50\n",
      "first 10 img of train set:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 img of test set:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Visualize some img\n",
    "\n",
    "classes = [0,1,2,3]\n",
    "num_classes = len(classes)\n",
    "\n",
    "def count_occurrences(x,y, set):\n",
    "    for label in range(len(classes)):\n",
    "        occurrences = x[y == label].shape[0]\n",
    "        print(f\"number of samples with label {label} in {set} set: {occurrences}\")\n",
    "\n",
    "padding = 0\n",
    "X_train_input = X_train\n",
    "Y_train_input = Y_train\n",
    "X_test_input = X_test\n",
    "Y_test_input = Y_test\n",
    "\n",
    "X_train_orig = np.copy(X_train_input.detach().numpy())\n",
    "X_test_orig = np.copy(X_test_input.detach().numpy())\n",
    "\n",
    "X_train_input = torch.reshape(X_train_input,(X_train_input.shape[0], -1))\n",
    "X_test_input = torch.reshape(X_test_input,(X_test_input.shape[0], -1))\n",
    "    \n",
    "if padding > 0:\n",
    "    print(\"WHY ARE U USING PADDING :(\")\n",
    "\n",
    "print(f\"Input shapes: X_train_input: {X_train_input.shape}, X_test_input: {X_test_input.shape},\"\n",
    "            +f\"Y_train_input: {Y_train_input.shape}, Y_test_input: {Y_test_input.shape}\") \n",
    "\n",
    "count_occurrences(X_train_input,Y_train_input, \"train\")\n",
    "count_occurrences(X_test_input,Y_test_input, \"test\")\n",
    "\n",
    "print('first 10 img of train set:')\n",
    "show_images(X_train_orig, Y_train_input)\n",
    "\n",
    "print('first 10 img of test set:')\n",
    "show_images(X_test_orig, Y_test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da7a6b1",
   "metadata": {
    "id": "8da7a6b1"
   },
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9952594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "NUM_QUBITS = 8\n",
    "NUM_LAYERS = 32             \n",
    "INPUT_DIM = 256\n",
    "#####################################\n",
    "\n",
    "NUM_CLASSES = num_classes\n",
    "\n",
    "\n",
    "class QVC(torch.nn.Module):\n",
    "    def __init__(self, input_dim=INPUT_DIM, output_dim=NUM_CLASSES, num_qubits=NUM_QUBITS, \n",
    "                 num_layers=NUM_LAYERS):\n",
    "        super().__init__()\n",
    "        self.num_qubits = num_qubits\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        # change device for higher performance!\n",
    "        self.device = qml.device(\"default.qubit\", wires=self.num_qubits)\n",
    "\n",
    "        @qml.qnode(self.device)\n",
    "        def circuit(inputs, weights):\n",
    "            qml.QubitStateVector(state=inputs, wires=range(self.num_qubits))\n",
    "            qml.StronglyEntanglingLayers(weights=weights, wires=range(self.num_qubits))\n",
    "            return [qml.expval(qml.PauliZ(i)) for i in range(self.output_dim)]\n",
    "            \n",
    "        self.weights_shape = qml.StronglyEntanglingLayers.shape(n_layers=self.num_layers, n_wires=self.num_qubits)\n",
    "        param_shapes = {\"weights\" : self.weights_shape}\n",
    "        init_vals = {\"weights\" : 0.01 * torch.rand(self.weights_shape)}\n",
    "        \n",
    "        self.qcircuit = qml.qnn.TorchLayer(qnode=circuit, weight_shapes=param_shapes, init_method=init_vals)\n",
    "        #drawer= qml.draw(circuit, show_all_wires=True, expansion_strategy=\"device\")\n",
    "        #dummy_weights = torch.zeros(self.weights_shape)\n",
    "        #dummy_inputs = torch.nn.functional.normalize(torch.ones(10,256))\n",
    "        #print(drawer(dummy_inputs[0],dummy_weights))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = torch.nn.functional.normalize(x, dim=0)\n",
    "        return self.qcircuit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93c7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.ones(10)\n",
    "#print(torch.nn.functional.normalize(x, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f6f324",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c88fd4c",
    "outputId": "ccd04bdd-8106-4855-ce9c-c81e0e50c2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QVC(\n",
      "  (qcircuit): <Quantum Torch Layer: func=circuit>\n",
      ")\n",
      "qcircuit.weights torch.Size([32, 8, 3])\n",
      "requires_grad: True\n",
      "feats_train shape: torch.Size([1000, 256])\n",
      "feats_test shape: torch.Size([200, 256])\n",
      "labels_train shape: torch.Size([1000])\n",
      "labels_test shape: torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "learning_rate = 0.001\n",
    "#####################################\n",
    "\n",
    "feats_train = X_train_input\n",
    "feats_test = X_test_input\n",
    "labels_train = Y_train_input\n",
    "labels_test = Y_test_input\n",
    "num_train = feats_train.shape[0]\n",
    "\n",
    "\n",
    "model = QVC()\n",
    "#model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())\n",
    "    print(f\"requires_grad: {param.requires_grad}\")\n",
    "\n",
    "print(f\"feats_train shape: {feats_train.shape}\")\n",
    "print(f\"feats_test shape: {feats_test.shape}\")\n",
    "print(f\"labels_train shape: {labels_train.shape}\")\n",
    "print(f\"labels_test shape: {labels_test.shape}\")\n",
    "\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    acc = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if torch.argmax(p) == l:\n",
    "            acc = acc + 1\n",
    "    acc = acc / len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1277018",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1277018",
    "outputId": "80628be2-b910-48c4-d4fd-c4ee52c7c13a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading state_dict of model for epoch 20 and eval on dataset, pls stand by..\n",
      "Epoch     0 | Approx Cost (train): 0.9936860 | Approx Cost (val): 1.0183240 | Acc train: 0.9900000 | Acc val: 1.0000000\n"
     ]
    }
   ],
   "source": [
    "# training loop and optimizer init\n",
    "\n",
    "########################\n",
    "PRETRAINED = True\n",
    "########################\n",
    "\n",
    "if PRETRAINED:\n",
    "    model.load_state_dict(torch.load(f'./model_checkpoints/QVC-Amp-8-32-0_0-ep20'))\n",
    "    print(f'Loading state_dict of model for epoch 20 and eval on dataset, pls stand by..')\n",
    "    epochs = 0\n",
    "else:\n",
    "    print(f'Beginning training loop for classes {classes}, {NUM_CLASSES} output qubits, {NUM_LAYERS} layers qvc')\n",
    "    epochs = 20\n",
    "    \n",
    "batch_size = 50\n",
    "num_batches = num_train//batch_size\n",
    "\n",
    "def gen_batches(num_samples, num_batches):\n",
    "    assert num_samples % num_batches == 0\n",
    "    perm_ind = torch.reshape(torch.randperm(num_samples), (num_batches, -1))\n",
    "    return perm_ind\n",
    "\n",
    "def print_acc(epoch, save_checkpoints=False):\n",
    "    with torch.no_grad():\n",
    "        if not PRETRAINED and save_checkpoints:\n",
    "            torch.save(model.state_dict(), f\"./model_checkpoints/QVC-Amp-new-8-32-0_0-ep{epoch}\")\n",
    "        predictions_train = [model(f) for f in feats_train[:100]]\n",
    "        predictions_test = [model(f) for f in feats_test[:100]]\n",
    "        cost_approx_train = criterion(torch.stack(predictions_train), labels_train[:100])\n",
    "        cost_approx_test = criterion(torch.stack(predictions_test), labels_test[:100])        \n",
    "        acc_approx_train = accuracy(labels_train[:100], predictions_train)\n",
    "        acc_approx_test = accuracy(labels_test[:100], predictions_test)\n",
    "        \n",
    "        print(\"Epoch {:5d} | Approx Cost (train): {:0.7f} | Approx Cost (val): {:0.7f} | Acc train: {:0.7f} | Acc val: {:0.7f}\"\n",
    "        \"\".format(epoch, cost_approx_train, cost_approx_test, acc_approx_train, acc_approx_test))\n",
    "    return predictions_train, predictions_test\n",
    "\n",
    "for ep in range(epochs):\n",
    "    batch_ind = gen_batches(num_train, num_batches)\n",
    "    _, _ = print_acc(epoch=ep)\n",
    "\n",
    "    for it in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "        feats_train_batch = feats_train[batch_ind[it]]\n",
    "        labels_train_batch = labels_train[batch_ind[it]]\n",
    "        \n",
    "        outputs = [model(f) for f in feats_train_batch]\n",
    "        loss = criterion(torch.stack(outputs),labels_train_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "pred_train_final, pred_test_final = print_acc(epochs)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6uYnCDuSq-g",
   "metadata": {
    "id": "d6uYnCDuSq-g"
   },
   "outputs": [],
   "source": [
    "#### ADVERSARIAL ATTACKS ####\n",
    "\n",
    "def FGSM(loss, eps, feats, labels, weights):\n",
    "    delta = torch.zeros_like(feats, requires_grad=True)\n",
    "    loss = criterion(model(feats + delta), labels)\n",
    "    loss.backward()\n",
    "    return epsilon * delta.grad.detach().sign()\n",
    "\n",
    "def PGD(model, feats, labels, epsilon=0.1, alpha=0.01, num_iter=10, randomize=False, positive=False):\n",
    "    if randomize:\n",
    "        delta = torch.rand_like(feats, requires_grad=True)\n",
    "        delta.data = delta.data * 2 * epsilon - epsilon\n",
    "    else:\n",
    "        delta = torch.zeros_like(feats, requires_grad=True)\n",
    "    for t in range(num_iter):\n",
    "        feats_adv = feats + delta\n",
    "        outputs = [model(f) for f in feats_adv]\n",
    "        loss = criterion(torch.stack(outputs),labels)\n",
    "        loss.backward()\n",
    "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
    "        if positive:\n",
    "            delta.data = torch.where((delta+feats)<0,-feats,delta)\n",
    "        delta.grad.zero_()\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c5e7ef1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m perturbed_X_train \u001b[38;5;241m=\u001b[39m \u001b[43mPGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeats_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m pred_check \u001b[38;5;241m=\u001b[39m [model(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m feats_train[:\u001b[38;5;241m100\u001b[39m]]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBenign accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy(labels_train[:\u001b[38;5;241m100\u001b[39m],\u001b[38;5;250m \u001b[39mpred_check)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36mPGD\u001b[0;34m(model, feats, labels, epsilon, alpha, num_iter, randomize, positive)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iter):\n\u001b[1;32m     16\u001b[0m     feats_adv \u001b[38;5;241m=\u001b[39m feats \u001b[38;5;241m+\u001b[39m delta\n\u001b[0;32m---> 17\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [model(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m feats_adv]\n\u001b[1;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(torch\u001b[38;5;241m.\u001b[39mstack(outputs),labels)\n\u001b[1;32m     19\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iter):\n\u001b[1;32m     16\u001b[0m     feats_adv \u001b[38;5;241m=\u001b[39m feats \u001b[38;5;241m+\u001b[39m delta\n\u001b[0;32m---> 17\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m feats_adv]\n\u001b[1;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(torch\u001b[38;5;241m.\u001b[39mstack(outputs),labels)\n\u001b[1;32m     19\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m, in \u001b[0;36mQVC.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m#print(x.shape)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqcircuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/qnn/torch.py:402\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    399\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(inputs, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# calculate the forward pass as usual\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# reshape to the correct number of batch dims\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_batch_dim:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/qnn/torch.py:423\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    419\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{arg: weight\u001b[38;5;241m.\u001b[39mto(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m    422\u001b[0m }\n\u001b[0;32m--> 423\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqnode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/qnode.py:1039\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         full_transform_program\u001b[38;5;241m.\u001b[39m_set_all_argnums(\n\u001b[1;32m   1035\u001b[0m             \u001b[38;5;28mself\u001b[39m, args, kwargs, argnums\n\u001b[1;32m   1036\u001b[0m         )  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/interfaces/execution.py:648\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, transform_program, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform, device_vjp)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;66;03m# Exiting early if we do not need to deal with an interface boundary\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_interface_boundary_required:\n\u001b[0;32m--> 648\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43minner_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(results)\n\u001b[1;32m    651\u001b[0m _grad_on_execution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/interfaces/execution.py:261\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes, **_)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_only:\n\u001b[1;32m    260\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(qml\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tapes)\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached_device_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/interfaces/execution.py:344\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m repeated \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tape \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tapes):\n\u001b[0;32m--> 344\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hashes\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;66;03m# Tape already exists within ``tapes``. Determine the\u001b[39;00m\n\u001b[1;32m    348\u001b[0m         \u001b[38;5;66;03m# index of the first occurrence of the tape, store this,\u001b[39;00m\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;66;03m# and continue to the next iteration.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m         idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(hashes\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;28mlist\u001b[39m(hashes\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;241m.\u001b[39mindex(h)]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/tape/qscript.py:222\u001b[0m, in \u001b[0;36mQuantumScript.hash\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"int: returns an integer hash uniquely representing the quantum script\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m fingerprint \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 222\u001b[0m \u001b[43mfingerprint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m fingerprint\u001b[38;5;241m.\u001b[39mextend(m\u001b[38;5;241m.\u001b[39mhash \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[1;32m    224\u001b[0m fingerprint\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/tape/qscript.py:222\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"int: returns an integer hash uniquely representing the quantum script\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m fingerprint \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 222\u001b[0m fingerprint\u001b[38;5;241m.\u001b[39mextend(\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperations)\n\u001b[1;32m    223\u001b[0m fingerprint\u001b[38;5;241m.\u001b[39mextend(m\u001b[38;5;241m.\u001b[39mhash \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[1;32m    224\u001b[0m fingerprint\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/operation.py:728\u001b[0m, in \u001b[0;36mOperator.hash\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhash\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    722\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"int: Integer hash that uniquely represents the operator.\"\"\"\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\n\u001b[1;32m    724\u001b[0m         (\n\u001b[1;32m    725\u001b[0m             \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    726\u001b[0m             \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwires\u001b[38;5;241m.\u001b[39mtolist()),\n\u001b[1;32m    727\u001b[0m             \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters\u001b[38;5;241m.\u001b[39mvalues()),\n\u001b[0;32m--> 728\u001b[0m             \u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    729\u001b[0m         )\n\u001b[1;32m    730\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pennylane/operation.py:393\u001b[0m, in \u001b[0;36m_process_data\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_data\u001b[39m(op):\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# Use qml.math.real to take the real part. We may get complex inputs for\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# example when differentiating holomorphic functions with JAX: a complex\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# valued QNode (one that returns qml.state) requires complex typed inputs.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRZ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhaseShift\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRot\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 393\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRZ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRot\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    396\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m([qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mround(qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreal(d) \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi), \u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m op\u001b[38;5;241m.\u001b[39mdata])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:426\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    423\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    424\u001b[0m     )\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:636\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    635\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:567\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    565\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    566\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    570\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:327\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    325\u001b[0m     )\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:116\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(\n\u001b[0;32m--> 116\u001b[0m         tensor_view, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m tensor_view\u001b[38;5;241m.\u001b[39mne(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "perturbed_X_train = PGD(model, feats=feats_train[:100], labels=labels_train[:100], epsilon=0.1, alpha=0.01, \n",
    "                  num_iter=10, randomize=False, positive=False)\n",
    "\n",
    "pred_check = [model(f) for f in feats_train[:100]]\n",
    "print(f'Benign accuracy: {accuracy(labels_train[:100], pred_check)}')\n",
    "pred_adv = [model(f) for f in perturbed_X_train[:100]+feats_train[:100]]\n",
    "print(f'Adv accuracy: {accuracy(labels_train[:100], pred_adv)}')\n",
    "\n",
    "# visualize the attack patterns\n",
    "perturbed_X_orig = torch.reshape(perturbed_X_train, (100,16,16)).detach().numpy() \n",
    "perturbed_img = X_train_orig[:100] + perturbed_X_orig[:100]\n",
    "show_images_pred(X=perturbed_img[10:], Y=labels_train[10:], pred=torch.stack(pred_adv[10:]).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc381637-50ba-48b3-9705-36eaceca05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can also check transferability by loading perturbations from other models\n",
    "\n",
    "\"\"\"\n",
    "path = './perturbations/perturbations-AmpEnc-no_reg-ep20-PGD0_1-100_samples.npy'\n",
    "perturbed_X_orig = np.load(path)\n",
    "perturbed_X_train = torch.reshape(torch.from_numpy(perturbed_X_orig).float(), (100,256))\n",
    "\n",
    "pred_check = [model(f) for f in feats_train[:100]]\n",
    "print(f'Benign accuracy: {accuracy(labels_train[:100], pred_check)}')\n",
    "\n",
    "pred_adv = [model(f) for f in perturbed_X_train[:100]+feats_train[:100]]\n",
    "print(f'Adv accuracy: {accuracy(labels_train[:100], pred_adv)}')\n",
    "\n",
    "# visualize the attack patterns\n",
    "perturbed_img = X_train_orig[:100] + perturbed_X_orig[:100]\n",
    "show_images_pred(X=perturbed_img[10:], Y=labels_train[10:], pred=pred_adv.detach().numpy()[10:])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_check = [model(f) for f in feats_train[:50]]\n",
    "predictions_adv = [model(f) for f in perturbed_X_train[:100]+feats_train[:100]]\n",
    "print(f'Sanity check: benign accuracy on train set (first 50 images): {accuracy(labels_train[:50], pred_check)}')\n",
    "print(f'Adversarial accuracy on train set (first 100 images): {accuracy(labels_train[:100], predictions_adv[:100])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077135ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_X_orig = torch.reshape(perturbed_X_train, (perturbed_X_train.shape[0],16,16))\n",
    "np.save(file=f\"./own_data_pert/perturbations_256_AmpEnc_no-reg_epoch50_PGD_0-2_0-01_100_samples_trainset_20_steps\", \n",
    "        arr=perturbed_X_orig.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce16f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perturbed_X_orig = np.load('./own_data_pert/perturbations_256_AmpEnc_no-reg_epoch20_PGD_0-1_0-01_100_samples_trainset_10_steps.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3607c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(load_epoch, pred_train_final, eps=0.1, alpha=0.01, steps=10, X=feats_train, Y=labels_train, download=False, \n",
    "            positive=False, heatmap=True, perturbations=perturbed_X_orig, num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a42b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(20, pred_train_final, 0.1, 0.01, 20, False, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(epoch='3-9', pred_check = predictions_train, eps=0.1, alpha= 0.02, steps=10, download=True, positive=True, heatmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75499013",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(epoch='3-9', pred_check = predictions_train, eps=0.8, alpha= 0.06, steps=20, download=True, positive=True, heatmap=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99974018",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(epoch='3-9', pred_check = predictions_train, eps=1.0, alpha= 0.08, steps=20, download=True, positive=True, heatmap=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928c4ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "5928c4ab",
    "outputId": "ec6a332b-b103-475e-8f07-8e853b244878"
   },
   "outputs": [],
   "source": [
    "\n",
    "np.save(file=\"weights_6QB_196inp-Reup-11Lay-400samples-FMNIST-0-1.npy\", arr=weights)\n",
    "#from google.colab import files\n",
    "#files.download('weights_6QB_196inp-Reup-11Lay-400samples-FMNIST-0-1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96336346",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(loc=0.0, scale=0.06, size=(14,14))\n",
    "show_single(X_train_filtered[0]+noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pvvy26to93JS",
   "metadata": {
    "id": "pvvy26to93JS"
   },
   "outputs": [],
   "source": [
    "# find out which features are important; set top m and lowest m pixels to white/black ,respectively\n",
    "\n",
    "#num_samples_for_feat_selec = 10\n",
    "num_iter = 50\n",
    "arr_inp_feats = np.zeros((400,11,6,3))\n",
    "X_feat_selec = feats_train\n",
    "Y_feat_selec = labels_train\n",
    "grad = np.zeros(arr_inp_feats.shape)\n",
    "#show_images(X_train_filtered[500:], Y_feat_selec)\n",
    "assert np.all(X_feat_selec == feats_train) \n",
    "\n",
    "for j in range(num_iter):\n",
    "    #noise = 0.05 * np.random.random((num_samples_for_feat_selec,11,6,3))\n",
    "    noise = np.random.normal(loc=0.0, scale=0.06, size=(11,6,3)) \n",
    "    #grad = qml.grad(cost, argnum=2)(weights, bias, X_feat_selec+noise, Y_feat_selec)\n",
    "    \n",
    "    # try this out:\n",
    "    for k in range(grad.shape[0]):\n",
    "        grad[k] = qml.grad(variational_classifier, argnum=2)(weights, bias, X_feat_selec[k]+noise[k])\n",
    "    #print(grad.shape)\n",
    "    arr_inp_feats += grad\n",
    "    \n",
    "assert np.all(X_feat_selec == feats_train)\n",
    "\n",
    "arr_inp_feats /= num_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_inp_feats_re = np.reshape(arr_inp_feats, (arr_inp_feats.shape[0],198))[:,:-2]\n",
    "sorted_ind = np.argsort(arr_inp_feats_re)\n",
    "#print(sorted_ind.shape)\n",
    "#print(arr_inp_feats_re[0])\n",
    "#print(sorted_ind[0])\n",
    "\n",
    "highest_ind = sorted_ind[:,-10:]\n",
    "lowest_ind = sorted_ind[:,:10]\n",
    "#print(highest_ind.shape)\n",
    "#print(lowest_ind.shape)\n",
    "#print(highest_ind[0])\n",
    "\n",
    "# blank max feats\n",
    "feats_blank_high = np.zeros((10,196))\n",
    "feats_blank_low = np.zeros((10,196))\n",
    "\n",
    "# set values in orig images\n",
    "feats_re = np.copy(X_feat_selec)\n",
    "feats_re = np.reshape(feats_re, (feats_re.shape[0], -1))[:,:-2]\n",
    "feats_re = feats_re[:10]\n",
    "\n",
    "for i in range(10):\n",
    "    if Y_feat_selec[i] == 1:\n",
    "        feats_blank_high[i,highest_ind[i]] = 1\n",
    "        feats_blank_low[i,lowest_ind[i]] = 1\n",
    "        feats_re[i,highest_ind[i]] = 0\n",
    "        feats_re[i,lowest_ind[i]] = 1\n",
    "    else:\n",
    "        feats_blank_high[i,lowest_ind[i]] = 1\n",
    "        feats_blank_low[i,highest_ind[i]] = 1\n",
    "        feats_re[i,highest_ind[i]] = 1\n",
    "        feats_re[i,lowest_ind[i]] = 0\n",
    "    \n",
    "feats_undo = np.reshape(feats_re,(feats_re.shape[0], 14,14))\n",
    "feats_blank_high = np.reshape(feats_blank_high,(10, 14,14))\n",
    "feats_blank_low = np.reshape(feats_blank_low,(10, 14,14))\n",
    "\n",
    "arr_inp_feats_re = np.reshape(arr_inp_feats_re, (arr_inp_feats_re.shape[0],14,14))\n",
    "\n",
    "#assert np.all(X_feat_selec == feats_train[:10])    #??????\n",
    "#pred_train = [variational_classifier(weights, bias, f) for f in feats_train[:10]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(arr_inp_feats_re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47375b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_pred(X_train_filtered[:10], Y_train_filtered[:10] ,predictions_train)\n",
    "show_images_heatmaps(arr_inp_feats_re,Y_feat_selec, predictions_train, None, False, None, None, only_img=True, switched=True, eps=0.18)\n",
    "show_images(feats_blank_high,Y_feat_selec)\n",
    "show_images(feats_blank_low,Y_feat_selec)\n",
    "\n",
    "feats_re_model = np.pad(feats_re,((0,0),(0,2)))\n",
    "feats_re_model = np.reshape(feats_re_model, (10,) + weights_shape)\n",
    "pred_changed = [variational_classifier(weights, bias, f) for f in feats_re_model[:10]]\n",
    "\n",
    "show_images_pred(feats_undo, Y_feat_selec, pred_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ea5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_important_pixels(orig, pixels):\n",
    "    f = np.concatenate([pixels[..., None],\n",
    "                        np.zeros((14, 14, 1)).astype(int),\n",
    "                        orig[..., None]], axis=-1)\n",
    "    plt.imshow(f)\n",
    "    plt.show()\n",
    "    \n",
    "def show_images_important_pixels(X, Y, pred, high, low, saved=False, name=None):\n",
    "    #predic = [np.argmax(p) for p in pred]\n",
    "    predic = [1 if p > 0.5 else 0 for p in pred]\n",
    "    num = 10\n",
    "    images = X[:num]\n",
    "    labels = Y[:num]\n",
    "    num_row = 2\n",
    "    num_col = 5# plot images\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "    for i in range(num):\n",
    "        ax = axes[i//num_col, i%num_col]\n",
    "        pixels_high = high[i]\n",
    "        pixels_low= low[i]\n",
    "        orig = X[i]\n",
    "        f = np.concatenate([pixels_low[..., None],\n",
    "                            pixels_high[..., None],\n",
    "                            orig[..., None]], axis=-1)\n",
    "        ax.imshow(f)\n",
    "        ax.set_title('Label: {}/ {}'.format(labels[i], predic[i]))\n",
    "    plt.tight_layout()\n",
    "    if saved:\n",
    "      plt.savefig(f\"{name}.png\")\n",
    "    else:\n",
    "      plt.show()\n",
    "    \n",
    "#show_important_pixels(X_train_filtered[1],feats_blank_low[1])\n",
    "show_images_important_pixels(X_train_filtered, Y_train_filtered, predictions_train, feats_blank_high, feats_blank_low, saved=False, name=None)\n",
    "#show_important_pixels(X_train_filtered[8],feats_blank_low[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MpX4B9_WSADU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "MpX4B9_WSADU",
    "outputId": "b9e610a9-4682-4721-f512-c26728f837e2"
   },
   "outputs": [],
   "source": [
    "#pred_train = [variational_classifier(weights, bias, f) for f in feats_train[:num_samples_for_feat_selec]]\n",
    "#show_images(X_train_filtered, Y_feat_selec)\n",
    "show_images_pred(np.abs(arr_inp_feats_re),Y_feat_selec, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-IO55VAFvMxJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "id": "-IO55VAFvMxJ",
    "outputId": "043322b7-7739-4acd-813c-67550d3048e2"
   },
   "outputs": [],
   "source": [
    "heatmap_ones = np.sum(arr_inp_feats_re[Y_feat_selec==1],axis=0)/len(arr_inp_feats_re[Y_feat_selec==1])\n",
    "heatmap_zeros = np.sum(arr_inp_feats_re[Y_feat_selec==0],axis=0)/len(arr_inp_feats_re[Y_feat_selec==1])\n",
    "show_single_heatmap(heatmap_zeros)\n",
    "show_single_heatmap(heatmap_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KBakONj6_Woi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "KBakONj6_Woi",
    "outputId": "229d653b-cd17-4807-ad47-e9d93b134aff"
   },
   "outputs": [],
   "source": [
    "show_single(np.abs(heatmap_ones+heatmap_zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0jOSzpSzCJVv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0jOSzpSzCJVv",
    "outputId": "72d4d341-311b-4623-cbe7-0dc1408e64bf"
   },
   "outputs": [],
   "source": [
    "show_images(X_train_filtered,Y_train_filtered)\n",
    "show_images(perturbed_X_orig, labels_train)\n",
    "show_images(X_train_filtered[:10] + perturbed_X_orig, Y_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q0T__qaFcyMB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "q0T__qaFcyMB",
    "outputId": "23b9751d-8836-41a3-8060-06e3e6e2cc6b"
   },
   "outputs": [],
   "source": [
    "predictions_adv = [variational_classifier(weights, bias, f) for f in perturbed_X]\n",
    "acc_adv = accuracy(Y_train_filtered, predictions_adv)\n",
    "\n",
    "#predictions_orig = [variational_classifier(weights, bias, f) for f in feats_train[:]]\n",
    "\n",
    "#X_train_orig = np.reshape(feats_train, (feats_train.shape[0],108))[:,:100]\n",
    "#X_train_orig = np.reshape(X_train_orig, (X_train_orig.shape[0],10,10))\n",
    "\n",
    "#X_train_orig = np.reshape(X_train_input, (X_train_input.shape[0],108))[:,:100]\n",
    "#X_train_orig = np.reshape(X_train_orig, (X_train_orig.shape[0],10,10))\n",
    "\n",
    "#show_images_pred(X_train_orig, Y_train_input, predictions_orig)\n",
    "show_images_pred(perturbed_X_orig+X_train_filtered[:10], Y_train_filtered, predictions_adv)\n",
    "#show_images_pred(perturbed_X_orig[10:], Y_train_input[10:], predictions_adv[10:])\n",
    "#show_images_pred(perturbed_X_orig[20:], Y_train_input[20:], predictions_adv[20:])\n",
    "print(f\"Adversarial accuracy: {acc_adv}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
